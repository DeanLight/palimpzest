from __future__ import annotations

from palimpzest.dataclasses import OperatorStats, PlanStats, SampleExecutionData
from palimpzest.operators import FilteredScan, FilterOp, LogicalOperator, PhysicalOperator
from palimpzest.operators.physical import PhysicalOperator

# backwards compatability for users who are still on Python 3.9
try:
    from itertools import pairwise
except:
    from more_itertools import pairwise

from typing import Any, Dict, List

import time


class Plan:
    """A generic Plan is a graph of nodes (#TODO a list for now).
    The main subclasses are a LogicalPlan, which is composed of logical Operators, and a PhysicalPlan, which is composed of physical Operators.
    Plans are typically generated by objects of class Planner, and consumed by several objects, e.g., Execution, CostEstimator, Optimizer, etc. etc.
    """

    operators = []

    def __init__(self):
        raise NotImplementedError

    def __iter__(self):
        return iter(self.operators)

    def __next__(self):
        return next(iter(self.operators))

    def __len__(self):
        return len(self.operators)

    def __repr__(self):
        if self.operators:
            return f"{self.__class__.__name__}:\n" + "\n".join(
                map(str, [f"{idx}. {str(op)}" for idx, op in enumerate(self.operators)])
            )
        else:
            return f"{self.__class__.__name__}: No operator tree."


class LogicalPlan(Plan):

    def __init__(self, operators: List[LogicalOperator] = []):
        self.operators = operators

    @staticmethod
    def fromOpsAndSubPlan(ops: List[LogicalOperator], subPlan: LogicalPlan) -> LogicalPlan:
        # create copies of all logical operators
        copySubPlan = [op.copy() for op in subPlan.operators]
        copyOps = [op.copy() for op in ops]

        # construct full set of operators
        copySubPlan.extend(copyOps)
        fullOperators = copySubPlan
        # make input and output schemas internally consistent
        for idx, op in enumerate(fullOperators):
            # if this op is a filter, set its outputSchema equal to its inputSchema
            if isinstance(op, FilteredScan):
                op.outputSchema = op.inputSchema

            # set next op's inputSchema to be this op's outputSchema
            if idx + 1 < len(fullOperators):
                nextOp = fullOperators[idx + 1]
                nextOp.inputSchema = op.outputSchema

        # return the LogicalPlan
        return LogicalPlan(fullOperators)


class PhysicalPlan(Plan):

    def __init__(self, operators: List[PhysicalOperator]):
        self.operators = operators
        self.total_time = None
        self.total_cost = None
        self.quality = None
        self.plan_stats = None

    @staticmethod
    def fromOpsAndSubPlan(ops: List[PhysicalOperator], subPlan: PhysicalPlan) -> PhysicalPlan:
        # create copies of all logical operators
        copySubPlan = [op.copy() for op in subPlan.operators]
        copyOps = [op.copy() for op in ops]

        # construct full set of operators
        copySubPlan.extend(copyOps)

        # return the PhysicalPlan
        return PhysicalPlan(operators=copySubPlan)

    def __str__(self) -> str:
        """Computes a string representation for this plan."""
        ops = [op for op in self.operators if not op.is_hardcoded()]
        label = "-".join([str(op) for op in ops])
        return f"PZ-{label}"

    def plan_id(self) -> str:
        return self.__str__()

    def getPlanModelNames(self) -> List[str]:
        model_names = []
        for op in self.operators:
            model = getattr(op, "model", None)
            if model is not None:
                model_names.append(model.value)

        return model_names

    def printPlan(self) -> None:
        """Print the physical plan."""
        print_ops = self.operators[1:]
        start = print_ops[0]
        print(f" 0. {type(start).__name__} -> {start.outputSchema.__name__} \n")

        for idx, (left, right) in enumerate(pairwise(print_ops)):
            in_schema = left.outputSchema
            out_schema = right.outputSchema
            print(
                f" {idx+1}. {in_schema.__name__} -> {type(right).__name__} -> {out_schema.__name__} ",
                end="",
            )
            # if right.desc is not None:
            #     print(f" ({right.desc})", end="")
            # check if right has a model attribute
            if right.is_hardcoded():
                print(f"\n    Using hardcoded function", end="")
            elif hasattr(right, "model"):
                print(f"\n    Using {right.model}", end="")
                if hasattr(right, "filter"):
                    filter_str = (
                        right.filter.filterCondition
                        if right.filter.filterCondition is not None
                        else str(right.filter.filterFn)
                    )
                    print(f'\n    Filter: "{filter_str}"', end="")
                if hasattr(right, "token_budget"):
                    print(f"\n    Token budget: {right.token_budget}", end="")
                if hasattr(right, "query_strategy"):
                    print(f"\n    Query strategy: {right.query_strategy}", end="")
            print()
            print(
                f"    ({','.join(in_schema.fieldNames())[:15]}...) -> ({','.join(out_schema.fieldNames())[:15]}...)"
            )
            print()

    def getSampleExecutionData(self) -> List[Dict[str, Any]]:
        """Compute and return all sample execution data collected by this plan so far."""
        # define helper function to extract answer from filter and convert operations
        def _get_answer(record_op_stats):
            # return T/F for filter
            if "_passed_filter" in record_op_stats.record_state:
                return record_op_stats.record_state["_passed_filter"]

            # return key->value mapping for generated fields for induce
            answer = {}
            if "generated_fields" in record_op_stats.op_details:
                for field in record_op_stats.op_details["generated_fields"]:
                    answer[field] = record_op_stats.record_state[field]

            return answer

        # construct table of observation data from sample batch of processed records
        sample_execution_data, source_op_id = [], None
        for op_id, operator_stats in self.plan_stats.operator_stats.items():
            # append observation data for each record
            for record_op_stats in operator_stats.record_op_stats_lst:
                # compute minimal observation which is supported by all operators
                # TODO: one issue with this setup is that cache_scans of previously computed queries
                #       may not match w/these observations due to the diff. op_name
                observation = SampleExecutionData(
                    record_uuid=record_op_stats.record_uuid,
                    record_parent_uuid=record_op_stats.record_parent_uuid,
                    op_id=op_id,
                    op_name=record_op_stats.op_name,
                    source_op_id=source_op_id,
                    op_time=record_op_stats.op_time,
                    passed_filter=(
                        record_op_stats.record_state["_passed_filter"]
                        if "_passed_filter" in record_op_stats.record_state
                        else None
                    ),
                    model_name=(
                        record_op_stats.op_details["model_name"]
                        if "model_name" in record_op_stats.op_details
                        else None
                    ),
                    filter_str=(
                        record_op_stats.op_details["filter_str"]
                        if "filter_str" in record_op_stats.op_details
                        else None
                    ),
                    input_fields_str=(
                        "-".join(sorted(record_op_stats.op_details["input_fields"]))
                        if "input_fields" in record_op_stats.op_details
                        else None
                    ),
                    generated_fields_str=(
                        "-".join(sorted(record_op_stats.op_details["generated_fields"]))
                        if "generated_fields" in record_op_stats.op_details
                        else None
                    ),
                    total_input_tokens=(
                        record_op_stats.record_stats["total_input_tokens"]
                        if "total_input_tokens" in record_op_stats.record_stats
                        else None
                    ),
                    total_output_tokens=(
                        record_op_stats.record_stats["total_output_tokens"]
                        if "total_output_tokens" in record_op_stats.record_stats
                        else None
                    ),
                    total_input_cost=(
                        record_op_stats.record_stats["total_input_cost"]
                        if "total_input_cost" in record_op_stats.record_stats
                        else None
                    ),
                    total_output_cost=(
                        record_op_stats.record_stats["total_output_cost"]
                        if "total_output_cost" in record_op_stats.record_stats
                        else None
                    ),
                    answer=_get_answer(record_op_stats)
                )

                # add observation to list of observations
                sample_execution_data.append(observation)

            # update source_op_id
            source_op_id = op_id

        return sample_execution_data


    def execute(self):
        """Execute the plan."""
        plan_start_time = time.time()

        # initialize plan and operator stats
        self.plan_stats = PlanStats(plan_id=self.plan_id())
        for op_idx, op in enumerate(self.operators):
            op_id = op.physical_op_id()
            self.plan_stats[op_id] = OperatorStats(op_idx=op_idx, op_id=op_id, op_name=op.op_name()) # TODO: also add op_details here

        # initialize list of output records
        output_records = []

        # TODO: execution issues I still need to resolve:
        #  - need to force upstream execution to complete for agg., groupby, and parallel operators
        #    -  eventually we could allow for pipelining and not block on parallel operators, but pre-SIGMOD let's keep that behavior intact
        # iterate over records from the datasource operator
        datasource_operator = self.operators[0]
        for record, record_op_stats in datasource_operator:
            self.plan_stats[datasource_operator.physical_op_id()] += record_op_stats

            # apply sequence of subsequent operators
            filtered = False
            for operator in self.operators[1:]:
                record, record_op_stats = operator(record)

                # add record_op_stats to appropriate operator
                self.plan_stats[datasource_operator.physical_op_id()] += record_op_stats

                # TODO: confirm if this isinstance will work with sub-class operations
                if isinstance(operator, FilterOp) and not record._passed_filter:
                    filtered = True
                    break

            if not filtered:
                output_records.append(record)

        # finalize plan stats
        total_plan_time = time.time() - plan_start_time
        self.plan_stats.finalize(total_plan_time)

        return output_records, self.plan_stats
