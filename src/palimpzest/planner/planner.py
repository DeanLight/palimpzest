from palimpzest.constants import Model, PromptStrategy, QueryStrategy
from palimpzest.operators import LogicalOperator, PhysicalOperator
from palimpzest.utils import getModels, getVisionModels
from .plan import LogicalPlan, PhysicalPlan

import palimpzest as pz
import palimpzest.operators as pz_ops
import palimpzest.corelib.schemas as schemas

from itertools import permutations
from typing import Any, Dict, List, Optional, Union

import numpy as np
import pandas as pd

import multiprocessing
import os


class Planner:
    """
    A Planner is responsible for generating a set of possible plans.
    The fundamental abstraction is, given an input of a graph (of datasets, or logical operators), it generates a set of possible graphs which correspond to the plan.
    These plans can be consumed from the planner using the __iter__ method.
    """

    def __init__(self):
        self.plans = []

    def generate_plans(self):
        return NotImplementedError

    def __iter__(self):
        return iter(self.plans)

    def __next__(self):
        return next(iter(self.plans))

    def __len__(self):
        return len(self.plans)


class LogicalPlanner(Planner):
    def __init__(self, no_cache: bool=False, *args, **kwargs):
        """A given planner should not have a dataset when it's being generated, since it could be used for multiple datasets.
        However, we currently cannot support this since the plans are stored within a single planner object.
        To support this, we can use a dictionary in the form [dataset -> [Plan, Plan, ...]].
        To discuss for future versions.
        """

        super().__init__(*args, **kwargs)
        self.no_cache = no_cache

    @staticmethod
    def _compute_legal_permutations(
        filterAndConvertOps: List[pz_ops.LogicalOperator],
    ) -> List[List[pz_ops.LogicalOperator]]:
        # There are a few rules surrounding which permutation(s) of logical operators are legal:
        # 1. if a filter depends on a field in a convert's outputSchema, it must be executed after the convert
        # 2. if a convert depends on another operation's outputSchema, it must be executed after that operation
        # 3. if depends_on is not specified for a convert operator, it cannot be swapped with another convert
        # 4. if depends_on is not specified for a filter, it can not be swapped with a convert (but it can be swapped w/adjacent filters)

        # compute implicit depends_on relationships, keep in mind that operations closer to the start of the list are executed first;
        # if depends_on is not specified for a convert or filter, it implicitly depends_on all preceding converts
        for idx, op in enumerate(filterAndConvertOps):
            if op.depends_on is None:
                all_prior_generated_fields = []
                for upstreamOp in filterAndConvertOps[:idx]:
                    if isinstance(upstreamOp, pz_ops.ConvertScan):
                        all_prior_generated_fields.extend(upstreamOp.generated_fields)
                op.depends_on = all_prior_generated_fields

        # compute all permutations of operators
        opPermutations = permutations(filterAndConvertOps)

        # iterate over permutations and determine if they are legal;
        # keep in mind that operations closer to the start of the list are executed first
        legalOpPermutations = []
        for opPermutation in opPermutations:
            is_valid = True
            for idx, op in enumerate(opPermutation):
                # if this op is a filter, we can skip because no upstream ops will conflict with this
                if isinstance(op, pz_ops.FilteredScan):
                    continue

                # invalid if upstream op depends on field generated by this op
                for upstreamOp in opPermutation[:idx]:
                    for col in upstreamOp.depends_on:
                        if col in op.generated_fields:
                            is_valid = False
                            break
                    if is_valid is False:
                        break
                if is_valid is False:
                    break

            # if permutation order is valid, then add it to the list of legal permutations
            if is_valid:
                legalOpPermutations.append(opPermutation)

        return legalOpPermutations

    @staticmethod
    def _compute_logical_plan_reorderings(logical_plan: LogicalPlan) -> List[LogicalPlan]:
        """
        Given the naive logical plan, compute all possible equivalent plans with filter
        and convert operations re-ordered.
        """
        operators = logical_plan.operators

        all_plans, op_idx = [], 0
        while op_idx < len(operators):
            op = operators[op_idx]

            # base case, if this is the first operator (currently must be a BaseScan or CacheScan)
            # then set all_plans to be the logical plan with just this operator
            if (isinstance(op, pz_ops.BaseScan) or isinstance(op, pz_ops.CacheScan)) and all_plans == []:
                all_plans = [LogicalPlan(operators=[op])]
                op_idx += 1

            # if this operator is not a FilteredScan or a ConvertScan: join op with each of the
            # re-orderings for its source operations
            elif not isinstance(op, pz_ops.FilteredScan) and not isinstance(op, pz_ops.ConvertScan):
                plans = []
                for subplan in all_plans:
                    new_logical_plan = LogicalPlan.fromOpsAndSubPlan([op], subplan)
                    plans.append(new_logical_plan)

                # update all_plans and op_idx
                all_plans = plans
                op_idx += 1

            # otherwise, if this operator is a FilteredScan or ConvertScan, make one plan per (legal)
            # permutation of consecutive converts and filters and recurse
            elif isinstance(op, pz_ops.FilteredScan) or isinstance(op, pz_ops.ConvertScan):
                # get list of consecutive converts and filters
                filterAndConvertOps = []
                nextOp, next_idx = op, op_idx
                while isinstance(nextOp, pz_ops.FilteredScan) or isinstance(nextOp, pz_ops.ConvertScan):
                    filterAndConvertOps.append(nextOp)
                    nextOp = operators[next_idx + 1] if next_idx + 1 < len(operators) else None
                    next_idx = next_idx + 1

                # compute set of legal permutations
                op_permutations = LogicalPlanner._compute_legal_permutations(filterAndConvertOps)

                # compute cross-product of op_permutations and subTrees by linking final op w/first op in subTree
                plans = []
                for ops in op_permutations:
                    for subplan in all_plans:
                        new_logical_plan = LogicalPlan.fromOpsAndSubPlan(ops, subplan)
                        plans.append(new_logical_plan)

                # update plans and operators (so that we skip over all operators in the re-ordering)
                all_plans = plans
                op_idx = next_idx

            else:
                raise Exception("PZ does not support the structure of this logical plan")

        return all_plans

    def _construct_logical_plan(self, dataset_nodes: List[pz.Set]) -> LogicalPlan:
        operators = []
        for idx, node in enumerate(dataset_nodes):
            uid = node.universalIdentifier()

            # Use cache if allowed
            if not self.no_cache and pz.datamanager.DataDirectory().hasCachedAnswer(uid):
                op = pz.operators.CacheScan(node.schema, datasetIdentifier=uid)
                operators.append(op)
                #return LogicalPlan(operators=operators)
                continue

            # First node is DataSource
            if idx == 0:
                assert isinstance(node, pz.datasources.DataSource)
                op = pz.operators.BaseScan(
                    outputSchema=node.schema,
                    datasetIdentifier=uid,
                )

            # if the Set's source is another Set, apply the appropriate scan to the Set
            else:
                inputSchema = dataset_nodes[idx - 1].schema
                outputSchema = node.schema

                if node._filter is not None:
                    op = pz_ops.FilteredScan(
                        inputSchema=inputSchema,
                        outputSchema=outputSchema,
                        filter=node._filter,
                        depends_on=node._depends_on,
                        targetCacheId=uid,
                    )
                elif node._groupBy is not None:
                    op = pz_ops.GroupByAggregate(
                        inputSchema=inputSchema,
                        outputSchema=outputSchema,
                        gbySig=node._groupBy,
                        targetCacheId=uid,
                    )
                elif node._aggFunc is not None:
                    op = pz_ops.ApplyAggregateFunction(
                        inputSchema=inputSchema,
                        outputSchema=outputSchema,
                        aggregationFunction=node._aggFunc,
                        targetCacheId=uid,
                    )
                elif node._limit is not None:
                    op = pz_ops.LimitScan(
                        inputSchema=inputSchema,
                        outputSchema=outputSchema,
                        limit=node._limit,
                        targetCacheId=uid,
                    )
                elif not outputSchema == inputSchema:
                    op = pz.operators.ConvertScan(
                        inputSchema=inputSchema,
                        outputSchema=outputSchema,
                        cardinality=node._cardinality,
                        image_conversion=node._image_conversion,
                        depends_on=node._depends_on,
                        targetCacheId=uid,
                    )
                else:
                    raise NotImplementedError("No logical operator exists for the specified dataset construction.")

            operators.append(op)

        return LogicalPlan(operators=operators)

    def generate_plans(self, dataset: pz.Dataset, sentinels: bool=False) -> List[LogicalPlan]:
        """Return a set of possible logical trees of operators on Sets."""
        # Obtain ordered list of datasets
        dataset_nodes = []
        node = dataset

        while isinstance(node, pz.sets.Dataset):
            dataset_nodes.append(node)
            node = node._source
        dataset_nodes.append(node)
        dataset_nodes = list(reversed(dataset_nodes))

        # construct naive logical plan
        plan = self._construct_logical_plan(dataset_nodes)

        # at the moment, we only consider sentinels for the naive logical plan
        if sentinels:
            self.plans = [plan]
            return self.plans

        # compute all possible logical re-orderings of this plan
        self.plans = LogicalPlanner._compute_logical_plan_reorderings(plan)
        print(f"LOGICAL PLANS: {len(self.plans)}")

        return self.plans


class PhysicalPlanner(Planner):
    def __init__(
        self,
            num_samples: Optional[int]=10,
            scan_start_idx: Optional[int]=0,
            sample_execution_data: Optional[List[Dict[str, Any]]]=None,
            allow_model_selection: Optional[bool]=True,
            allow_code_synth: Optional[bool]=True,
            allow_token_reduction: Optional[bool]=True,
            shouldProfile: Optional[bool]=True,
            useParallelOps: Optional[bool]=False,
        *args,
        **kwargs,
    ):
        super().__init__(*args, **kwargs)
        self.num_samples = num_samples
        self.scan_start_idx = scan_start_idx
        self.sample_execution_data = sample_execution_data
        self.allow_model_selection = allow_model_selection
        self.allow_code_synth = allow_code_synth
        self.allow_token_reduction = allow_token_reduction
        self.shouldProfile = shouldProfile
        self.useParallelOps = useParallelOps

        self.physical_ops = pz.operators.PHYSICAL_OPERATORS

    def _getAllowedModels(self, subplan: PhysicalPlan) -> List[Model]:
        """
        This function handles the logic of determining which model(s) can be used for a Convert or Filter
        operation during physical plan construction.

        The logic for determining which models can be used is as follows:
        - If model selection is allowed --> then all models may be used
        - If the subplan does not yet have an operator which uses a (non-vision) model --> then all models may be used
        - If the subplan has an operator which uses a (non-vision) model --> only the subplan's model may be used
        """
        # return all models if model selection is allowed
        if self.allow_model_selection:
            return getModels()

        # otherwise, get models used by subplan
        subplan_model, vision_models = None, getVisionModels()
        for phys_op in subplan.operators:
            model = getattr(phys_op, "model", None)
            if model is not None and model not in vision_models:
                subplan_model = model
                break

        # return all models if subplan does not have any models yet
        if subplan_model is None:
            return getModels()

        # otherwise return the subplan model
        return [subplan_model]

    def _resolveLogicalBaseScanOp(
        self,
        logical_base_scan_op: pz_ops.BaseScan,
        shouldProfile: bool = False,
        sentinel: bool = False,
    ) -> PhysicalOperator:
        """
        Given the logical operator for a base scan, determine which (set of) physical operation(s)
        the PhysicalPlanner can use to implement that logical operation.
        """
        if sentinel:
            shouldProfile = True

        op = pz_ops.MarshalAndScanDataOp(
            logical_base_scan_op.outputSchema,
            logical_base_scan_op.datasetIdentifier,
            num_samples=self.num_samples,
            scan_start_idx=self.scan_start_idx,
            shouldProfile=shouldProfile,
        )

        return op

    def _resolveLogicalCacheScanOp(
        self,
        logical_cache_scan_op: pz_ops.CacheScan,
        shouldProfile: bool = False,
        sentinel: bool = False,
    ) -> PhysicalOperator:
        """
        Given the logical operator for a cache scan, determine which (set of) physical operation(s)
        the PhysicalPlanner can use to implement that logical operation.
        """
        if sentinel:
            shouldProfile = True

        op = pz_ops.CacheScanDataOp(
            logical_cache_scan_op.outputSchema,
            logical_cache_scan_op.cachedDataIdentifier,
            num_samples=self.num_samples,
            scan_start_idx=self.scan_start_idx,
            shouldProfile=shouldProfile,
        )

        return op

    def _resolveLogicalConvertOp(
        self,
        logical_convert_op: pz_ops.ConvertScan,
        model: Optional[Model] = None,
        prompt_strategy: Optional[PromptStrategy] = None,
        query_strategy: Optional[QueryStrategy] = None,
        token_budget: Optional[float] = 1.0,
        shouldProfile: bool = False,
        sentinel: bool = False,
    ) -> PhysicalOperator:
        """
        Given the logical operator for a convert, determine which (set of) physical operation(s)
        the PhysicalPlanner can use to implement that logical operation.
        """
        if sentinel:
            shouldProfile = True

        # get input and output schemas for convert
        inputSchema = logical_convert_op.inputSchema
        outputSchema = logical_convert_op.outputSchema

        # TODO: test schema equality
        # use simple convert if the input and output schemas are the same
        if inputSchema == outputSchema:
            op = pz_ops.SimpleTypeConvert(
                inputSchema=inputSchema,
                outputSchema=outputSchema,
                targetCacheId=logical_convert_op.targetCacheId,
                shouldProfile=shouldProfile,
            )

        # if input and output schema are covered by a hard-coded convert; use that
        elif isinstance(inputSchema, schemas.File) and isinstance(outputSchema, schemas.TextFile):
            op = pz_ops.ConvertFileToText(
                inputSchema=inputSchema,
                outputSchema=outputSchema,
                targetCacheId=logical_convert_op.targetCacheId,
                shouldProfile=shouldProfile,
            )

        elif isinstance(inputSchema, schemas.ImageFile) and isinstance(outputSchema, schemas.EquationImage):
            op = pz_ops.ConvertImageToEquation(
                inputSchema=inputSchema,
                outputSchema=outputSchema,
                targetCacheId=logical_convert_op.targetCacheId,
                shouldProfile=shouldProfile,
            )

        elif isinstance(inputSchema, schemas.Download) and isinstance(outputSchema, schemas.File):
            op = pz_ops.ConvertDownloadToFile(
                inputSchema=inputSchema,
                outputSchema=outputSchema,
                targetCacheId=logical_convert_op.targetCacheId,
                shouldProfile=shouldProfile,
            )

        elif isinstance(inputSchema, schemas.File) and isinstance(outputSchema, schemas.XLSFile):
            op = pz_ops.ConvertFileToXLS(
                inputSchema=inputSchema,
                outputSchema=outputSchema,
                targetCacheId=logical_convert_op.targetCacheId,
                shouldProfile=shouldProfile,
            )

        elif isinstance(inputSchema, schemas.XLSFile) and isinstance(outputSchema, schemas.Table):
            op = pz_ops.ConvertXLSToTable(
                inputSchema=inputSchema,
                outputSchema=outputSchema,
                cardinality=logical_convert_op.cardinality,
                targetCacheId=logical_convert_op.targetCacheId,
                shouldProfile=shouldProfile,
            )

        elif isinstance(inputSchema, schemas.File) and isinstance(outputSchema, schemas.PDFFile):
            op = pz_ops.ConvertFileToPDF(
                inputSchema=inputSchema,
                outputSchema=outputSchema,
                pdfprocessor=pz.DataDirectory().current_config.get("pdfprocessing"),
                targetCacheId=logical_convert_op.targetCacheId,
                shouldProfile=shouldProfile,
            )

        # otherwise, create convert op for the given set of hyper-parameters
        else:
            op = pz_ops.LLMTypeConversion(
                inputSchema=inputSchema,
                outputSchema=outputSchema,
                shouldProfile=shouldProfile,
                model=model,
                prompt_strategy=prompt_strategy,
                query_strategy=query_strategy,
                token_budget=token_budget,
                cardinality=logical_convert_op.cardinality,
                image_conversion=logical_convert_op.image_conversion,
                desc=logical_convert_op.desc,
                targetCacheId=logical_convert_op.targetCacheId,
            )

        return op

    def _resolveLogicalFilterOp(
        self,
            logical_filter_op: ops.FilteredScan,
        model: Optional[Model] = None,
        prompt_strategy: Optional[PromptStrategy] = None,
        shouldProfile: bool = False,
        sentinel: bool = False,
    ) -> PhysicalOperator:
        """
        Given the logical operator for a filter, determine which (set of) physical operation(s)
        the PhysicalPlanner can use to implement that logical operation.
        """
        if sentinel:
            shouldProfile = True

        use_llm_filter = logical_filter_op.filter.filterFn is None
        op = (
            pz_ops.LLMFilter(
                inputSchema=logical_filter_op.inputSchema,
                outputSchema=logical_filter_op.outputSchema,
                filter=logical_filter_op.filter,
                model=model,
                prompt_strategy=prompt_strategy,
                targetCacheId=logical_filter_op.targetCacheId,
                shouldProfile=shouldProfile,
                max_workers=multiprocessing.cpu_count() if self.useParallelOps else 1,
            )
            if use_llm_filter
            else pz_ops.NonLLMFilter(
                inputSchema=logical_filter_op.inputSchema,
                outputSchema=logical_filter_op.outputSchema,
                filter=logical_filter_op.filter,
                targetCacheId=logical_filter_op.targetCacheId,
                shouldProfile=shouldProfile,
                max_workers=multiprocessing.cpu_count() if self.useParallelOps else 1,
            )
        )

        return op

    def _resolveLogicalLimitScanOp(
        self,
        logical_limit_scan_op: pz_ops.LimitScan,
        shouldProfile: bool = False,
        sentinel: bool = False,
    ) -> PhysicalOperator:
        """
        Given the logical operator for a limit scan, determine which (set of) physical operation(s)
        the PhysicalPlanner can use to implement that logical operation.
        """
        if sentinel:
            shouldProfile = True

        op = pz_ops.LimitScanOp(
            inputSchema=logical_limit_scan_op.inputSchema,
            outputSchema=logical_limit_scan_op.outputSchema,
            limit=logical_limit_scan_op.limit,
            targetCacheId=logical_limit_scan_op.targetCacheId,
            shouldProfile=shouldProfile,
        )

        return op

    def _resolveLogicalGroupByAggOp(
        self,
        logical_gby_agg_op: pz_ops.GroupByAggregate,
        shouldProfile: bool = False,
        sentinel: bool = False,
    ) -> PhysicalOperator:
        """
        Given the logical operator for a group by, determine which (set of) physical operation(s)
        the PhysicalPlanner can use to implement that logical operation.
        """
        if sentinel:
            shouldProfile = True

        op = pz_ops.ApplyGroupByOp(
            inputSchema=logical_gby_agg_op.inputSchema,
            gbySig=logical_gby_agg_op.gbySig,
            targetCacheId=logical_gby_agg_op.targetCacheId,
            shouldProfile=shouldProfile,
        )

        return op

    def _resolveLogicalApplyAggFuncOp(
        self,
        logical_apply_agg_fn_op: pz_ops.ApplyAggregateFunction,
        shouldProfile: bool = False,
        sentinel: bool = False,
    ) -> PhysicalOperator:
        """
        Given the logical operator for a group by, determine which (set of) physical operation(s)
        the PhysicalPlanner can use to implement that logical operation.
        """
        if sentinel:
            shouldProfile = True

        # TODO: use an Enum to list possible funcDesc(s)
        physicalOp = None
        if logical_apply_agg_fn_op.aggregationFunction.funcDesc == "COUNT":
            physicalOp = pz_ops.ApplyCountAggregateOp
        elif logical_apply_agg_fn_op.aggregationFunction.funcDesc == "AVERAGE":
            physicalOp = pz_ops.ApplyAverageAggregateOp

        op = physicalOp(
            inputSchema=logical_apply_agg_fn_op.inputSchema,
            aggFunction=logical_apply_agg_fn_op.aggregationFunction,
            targetCacheId=logical_apply_agg_fn_op.targetCacheId,
            shouldProfile=shouldProfile,
        )

        return op

    def _createBaselinePlan(self, logical_plan: LogicalPlan, model: Model) -> PhysicalPlan:
        """A simple wrapper around _createSentinelPlan as right now these are one and the same."""
        return self._createSentinelPlan(logical_plan, model)

    def _createSentinelPlan(self, logical_plan: LogicalPlan, model: Model) -> PhysicalPlan:
        """
        Create the sentinel plan for the given model. At least for now --- each
        sentinel plan is a plan with a single model which follows the naive logical
        plan implied by the user's program.
        """
        physical_operators = []
        for logical_op in logical_plan.operators:
            op = None
            if isinstance(logical_op, pz_ops.BaseScan):
                op = self._resolveLogicalBaseScanOp(logical_op, sentinel=True)

            elif isinstance(logical_op, pz_ops.CacheScan):
                op = self._resolveLogicalCacheScanOp(logical_op, sentinel=True)

            elif isinstance(logical_op, pz_ops.ConvertScan):
                op = self._resolveLogicalConvertOp(
                    logical_op,
                    model=model,
                    prompt_strategy=PromptStrategy.DSPY_COT_QA,
                    query_strategy=QueryStrategy.BONDED_WITH_FALLBACK,
                    token_budget=1.0,
                    sentinel=True,
                )

            elif isinstance(logical_op, pz_ops.FilteredScan):
                op = self._resolveLogicalFilterOp(
                    logical_op,
                    model=model,
                    prompt_strategy=PromptStrategy.DSPY_COT_BOOL,
                    sentinel=True,
                )

            elif isinstance(logical_op, pz_ops.LimitScan):
                op = self._resolveLogicalLimitScanOp(logical_op, sentinel=True)

            elif isinstance(logical_op, pz_ops.GroupByAggregate):
                op = self._resolveLogicalGroupByAggOp(logical_op, sentinel=True)

            elif isinstance(logical_op, pz_ops.ApplyAggregateFunction):
                op = self._resolveLogicalApplyAggFuncOp(logical_op, sentinel=True)

            physical_operators.append(op)

        return PhysicalPlan(operators=physical_operators)

    def _createPhysicalPlans(self, logical_plan: LogicalPlan) -> List[PhysicalPlan]:
        """
        Given the logical plan implied by this LogicalOperator, enumerate up to `max`
        possible physical plans and return them as a list.
        """
        # check that at least one llm service has been provided
        assert (
            len(getModels()) > 0
        ), "No models available to create physical plans! You must set at least one of the following environment variables: [OPENAI_API_KEY, TOGETHER_API_KEY, GOOGLE_API_KEY]"

        # determine which query strategies may be used
        query_strategies = [QueryStrategy.BONDED_WITH_FALLBACK]
        if self.allow_code_synth:
            query_strategies.append(QueryStrategy.CODE_GEN_WITH_FALLBACK)

        token_budgets = [1.0]
        if self.allow_token_reduction:
            token_budgets.extend([0.1, 0.5, 0.9])

        # get logical operators
        operators = logical_plan.operators

        all_plans = []
        for logical_op in operators:
            # base case, if this operator is a BaseScan set all_plans to be the physical plan with just this operator
            if isinstance(logical_op, pz_ops.BaseScan):
                physical_op = self._resolveLogicalBaseScanOp(logical_op, shouldProfile=self.shouldProfile)
                all_plans = [PhysicalPlan(operators=[physical_op])]

            # base case (possibly), if this operator is a CacheScan and all_plans is empty, set all_plans to be
            # the physical plan with just this operator; if all_plans is NOT empty, then merge w/all_plans
            elif isinstance(logical_op, pz_ops.CacheScan):
                physical_op = self._resolveLogicalCacheScanOp(logical_op, shouldProfile=self.shouldProfile)
                if all_plans == []:
                    all_plans = [PhysicalPlan(operators=[physical_op])]
                else:
                    plans = []
                    for subplan in all_plans:
                        new_physical_plan = PhysicalPlan.fromOpsAndSubPlan([physical_op], subplan)
                        plans.append(new_physical_plan)

                    # update all_plans
                    all_plans = plans

            elif isinstance(logical_op, pz_ops.ConvertScan):
                plans = []
                for subplan in all_plans:
                    # TODO: if hard-coded conversion, don't iterate over all plan possibilities
                    for qs in query_strategies:
                        # for code generation: we do not need to iterate over models and token budgets
                        if qs in [QueryStrategy.CODE_GEN_WITH_FALLBACK, QueryStrategy.CODE_GEN]:
                            physical_op = self._resolveLogicalConvertOp(
                                logical_op,
                                query_strategy=qs,
                                shouldProfile=self.shouldProfile,
                            )
                            new_physical_plan = PhysicalPlan.fromOpsAndSubPlan([physical_op], subplan)
                            plans.append(new_physical_plan)
                            continue

                        # for non-code generation query strategies, consider models and token budgets
                        models = self._getAllowedModels(subplan=subplan)
                        for model in models:
                            for token_budget in token_budgets:
                                physical_op = self._resolveLogicalConvertOp(
                                    logical_op,
                                    model=model,
                                    query_strategy=qs,
                                    token_budget=token_budget,
                                    shouldProfile=self.shouldProfile,
                                )
                                new_physical_plan = PhysicalPlan.fromOpsAndSubPlan([physical_op], subplan)
                                plans.append(new_physical_plan)

                # update all_plans
                all_plans = plans

            elif isinstance(logical_op, pz_ops.FilteredScan):
                plans = []
                for subplan in all_plans:
                    # TODO: if non-llm filter, don't iterate over all plan possibilities
                    models = self._getAllowedModels(subplan=subplan)
                    for model in models:
                        physical_op = self._resolveLogicalFilterOp(
                            logical_op,
                            model=model,
                            prompt_strategy=PromptStrategy.DSPY_COT_BOOL,
                            shouldProfile=self.shouldProfile,
                        )
                        new_physical_plan = PhysicalPlan.fromOpsAndSubPlan([physical_op], subplan)
                        plans.append(new_physical_plan)

                # update all_plans
                all_plans = plans

            elif isinstance(logical_op, ops.LimitScan):
                physical_op = self._resolveLogicalLimitScanOp(logical_op, shouldProfile=self.shouldProfile)

                plans = []
                for subplan in all_plans:
                    new_physical_plan = PhysicalPlan.fromOpsAndSubPlan([physical_op], subplan)
                    plans.append(new_physical_plan)

                # update all_plans
                all_plans = plans

            elif isinstance(logical_op, pz_ops.GroupByAggregate):
                physical_op = self._resolveLogicalGroupByAggOp(logical_op, shouldProfile=self.shouldProfile)

                plans = []
                for subplan in all_plans:
                    new_physical_plan = PhysicalPlan.fromOpsAndSubPlan([physical_op], subplan)
                    plans.append(new_physical_plan)

                # update all_plans
                all_plans = plans

            elif isinstance(logical_op, pz_ops.ApplyAggregateFunction):
                physical_op = self._resolveLogicalApplyAggFuncOp(logical_op, shouldProfile=self.shouldProfile)

                plans = []
                for subplan in all_plans:
                    new_physical_plan = PhysicalPlan.fromOpsAndSubPlan([physical_op], subplan)
                    plans.append(new_physical_plan)

                # update all_plans
                all_plans = plans

        return all_plans

    # TODO
    def compute_operator_estimates(self, sentinel_logical_plans: List[LogicalPlan]) -> Dict[str, Dict[str, Any]]:
        """
        Compute per-operator estimates of runtime, cost, and quality.
        """
        # for now, each sentinel uses the same logical plan, so we can simply use the first one
        logical_plan = sentinel_logical_plans[0]

        # compute estimates for every operator
        operator_estimates = {}
        if self.sample_execution_data is not None and self.sample_execution_data != []:
            # construct full dataset of samples
            df = pd.DataFrame(self.sample_execution_data)

            # get unique set of operator filters:
            # - for base/cache scans this is very simple
            # - for filters, this is based on the unique filter string or function (per-model)
            # - for induce, this is based on the generated field(s) (per-model)
            operator_estimates = {}
            for logical_op in logical_plan.operators:
                op_filter, estimates = None, None
                if isinstance(logical_op, pz_ops.BaseScan):
                    op_filter = "op_name == 'base_scan'"
                    op_df = df.query(op_filter)
                    if not op_df.empty:
                        estimates = {
                            "time_per_record": StatsProcessor._est_time_per_record(
                                op_df
                            )
                        }
                    operator_estimates[op_filter] = estimates

                elif isinstance(logical_op, ops.CacheScan):
                    op_filter = "op_name == 'cache_scan'"
                    op_df = df.query(op_filter)
                    if not op_df.empty:
                        estimates = {
                            "time_per_record": StatsProcessor._est_time_per_record(
                                op_df
                            )
                        }
                    operator_estimates[op_filter] = estimates

                elif isinstance(logical_op, pz_ops.ConvertScan):
                    generated_fields_str = "-".join(sorted(logical_op.generated_fields))
                    op_filter = f"(generated_fields == '{generated_fields_str}') & (op_name == 'induce' | op_name == 'p_induce')"
                    op_df = df.query(op_filter)
                    if not op_df.empty:
                        # compute estimates per-model, and add None which forces computation of avg. across all models
                        models = getModels(include_vision=True) + [None]
                        estimates = {model: None for model in models}
                        for model in models:
                            model_name = model.value if model is not None else None
                            est_tokens = StatsProcessor._est_num_input_output_tokens(
                                op_df, model_name=model_name
                            )
                            model_estimates = {
                                "time_per_record": StatsProcessor._est_time_per_record(
                                    op_df, model_name=model_name
                                ),
                                "cost_per_record": StatsProcessor._est_usd_per_record(
                                    op_df, model_name=model_name
                                ),
                                "est_num_input_tokens": est_tokens[0],
                                "est_num_output_tokens": est_tokens[1],
                                "selectivity": StatsProcessor._est_selectivity(
                                    df, op_df, model_name=model_name
                                ),
                                "quality": StatsProcessor._est_quality(
                                    op_df, model_name=model_name
                                ),
                            }
                            estimates[model_name] = model_estimates
                    operator_estimates[op_filter] = estimates

                elif isinstance(logical_op, pz_ops.FilteredScan):
                    filter_str = (
                        logical_op.filter.filterCondition
                        if logical_op.filter.filterCondition is not None
                        else str(logical_op.filter.filterFn)
                    )
                    op_filter = f"(filter == '{str(filter_str)}') & (op_name == 'filter' | op_name == 'p_filter')"
                    op_df = df.query(op_filter)
                    if not op_df.empty:
                        models = (
                            getModels()
                            if logical_op.filter.filterCondition is not None
                            else [None]
                        )
                        estimates = {model: None for model in models}
                        for model in models:
                            model_name = model.value if model is not None else None
                            est_tokens = StatsProcessor._est_num_input_output_tokens(
                                op_df, model_name=model_name
                            )
                            model_estimates = {
                                "time_per_record": StatsProcessor._est_time_per_record(
                                    op_df, model_name=model_name
                                ),
                                "cost_per_record": StatsProcessor._est_usd_per_record(
                                    op_df, model_name=model_name
                                ),
                                "est_num_input_tokens": est_tokens[0],
                                "est_num_output_tokens": est_tokens[1],
                                "selectivity": StatsProcessor._est_selectivity(
                                    df, op_df, model_name=model_name
                                ),
                                "quality": StatsProcessor._est_quality(
                                    op_df, model_name=model_name
                                ),
                            }
                            estimates[model_name] = model_estimates
                    operator_estimates[op_filter] = estimates

                elif isinstance(logical_op, pz_ops.LimitScan):
                    op_filter = "(op_name == 'limit')"
                    op_df = df.query(op_filter)
                    if not op_df.empty:
                        estimates = {
                            "time_per_record": StatsProcessor._est_time_per_record(
                                op_df
                            )
                        }
                    operator_estimates[op_filter] = estimates

                elif (
                    isinstance(logical_op, pz_ops.ApplyAggregateFunction)
                    and logical_op.aggregationFunction.funcDesc == "COUNT"
                ):
                    op_filter = "(op_name == 'count')"
                    op_df = df.query(op_filter)
                    if not op_df.empty:
                        estimates = {
                            "time_per_record": StatsProcessor._est_time_per_record(
                                op_df
                            )
                        }
                    operator_estimates[op_filter] = estimates

                elif (
                    isinstance(logical_op, pz_ops.ApplyAggregateFunction)
                    and logical_op.aggregationFunction.funcDesc == "AVERAGE"
                ):
                    op_filter = "(op_name == 'average')"
                    op_df = df.query(op_filter)
                    if not op_df.empty:
                        estimates = {
                            "time_per_record": StatsProcessor._est_time_per_record(
                                op_df
                            )
                        }
                    operator_estimates[op_filter] = estimates

        return operator_estimates

    # TODO
    def estimate_plan_costs(self, physical_plans: List[PhysicalPlan], operator_estimates: Dict[str, Dict[str, Any]]) -> List[PhysicalPlan]:
        """Estimate the cost (in terms of USD, latency, throughput, etc.) for each plan."""
        sample_execution_data = (
            None if operator_estimates == {} else operator_estimates
        )
        for physical_plan in physical_plans:
            physical_plan.estimateCost(sample_execution_data=sample_execution_data)

        return physical_plans

    def deduplicate_plans(self, physical_plans: List[PhysicalPlan]) -> List[PhysicalPlan]:
        """De-duplicate plans with identical estimates for runtime, cost, and quality."""
        # drop duplicate plans in terms of time, cost, and quality, as these can cause
        # plans on the pareto frontier to be dropped if they are "dominated" by a duplicate
        dedup_plans, dedup_tuple_set = [], set()
        for plan in physical_plans:
            plan_tuple = (plan.estimates['total_time'], plan.estimates['total_cost'], plan.estimates['quality'])
            if plan_tuple not in dedup_tuple_set:
                dedup_tuple_set.add(plan_tuple)
                dedup_plans.append(plan)

        print(f"DEDUP PLANS: {len(dedup_plans)}")
        return dedup_plans

    def select_pareto_optimal_plans(self, physical_plans: List[PhysicalPlan]) -> List[PhysicalPlan]:
        """Select the subset of physical plans which lie on the pareto frontier of our runtime, cost, and quality estimates."""
        # compute the pareto frontier of candidate physical plans and return the list of such plans
        # - brute force: O(d*n^2);
        #   - for every tuple, check if it is dominated by any other tuple;
        #   - if it is, throw it out; otherwise, add it to pareto frontier
        #
        # more efficient algo.'s exist, but they are non-trivial to implement, so for now I'm using
        # brute force; it may ultimately be best to compute a cheap approx. of the pareto front:
        # - e.g.: https://link.springer.com/chapter/10.1007/978-3-642-12002-2_6
        pareto_frontier_plans = []
        for i, plan_i in enumerate(physical_plans):
            paretoFrontier = True

            # check if any other plan dominates plan i
            for j, plan_j in enumerate(physical_plans):
                if i == j:
                    continue

                # if plan i is dominated by plan j, set paretoFrontier = False and break
                if (
                    plan_j.estimates['total_time'] <= plan_i.estimates['total_time']
                    and plan_j.estimates['total_cost'] <= plan_i.estimates['total_cost']
                    and plan_j.estimates['quality'] >= plan_i.estimates['quality']
                ):
                    paretoFrontier = False
                    break

            # add plan i to pareto frontier if it's not dominated
            if paretoFrontier:
                pareto_frontier_plans.append(plan_i)

        print(f"PARETO PLANS: {len(pareto_frontier_plans)}")

        # return the set of plans on the estimated pareto frontier
        return pareto_frontier_plans

    def add_baseline_plans(self, final_plans: List[PhysicalPlan]) -> List[PhysicalPlan]:
        # helper function to determine if this plan is already in the final set of plans
        def is_in_final_plans(plan, final_plans):
            for final_plan in final_plans:
                if plan == final_plan:
                    return True
            return False

        # if specified, include all baseline plans in the final set of plans
        for plan in [self._createBaselinePlan(model) for model in getModels()]:
            if is_in_final_plans(plan, final_plans):
                continue
            else:
                final_plans.append(plan)

        return final_plans

    def add_plans_closest_to_frontier(
        self,
        final_plans: List[PhysicalPlan],
        physical_plans: List[PhysicalPlan],
        min_plans: int,
    ) -> List[PhysicalPlan]:
        # helper function to determine if this plan is already in the final set of plans
        def is_in_final_plans(plan, final_plans):
            for final_plan in final_plans:
                if plan == final_plan:
                    return True
            return False

        # if specified, grab up to `min` total plans, and choose the remaining plans
        # based on their smallest agg. distance to the pareto frontier; distance is computed
        # by summing the pct. difference to the pareto frontier across each dimension
        min_distances = []
        for idx, plan in enumerate(physical_plans):
            # determine if this plan is already in the final set of plans
            if is_in_final_plans(plan, final_plans):
                continue

            # otherwise compute min distance to plans on pareto frontier
            min_dist, min_dist_idx = np.inf, -1
            for pareto_plan in final_plans:
                time_dist = (plan.estimates['total_time'] - pareto_plan.estimates['total_time']) / pareto_plan.estimates['total_time']
                cost_dist = (plan.estimates['total_cost'] - pareto_plan.estimates['total_cost']) / pareto_plan.estimates['total_cost']
                quality_dist = (
                    (pareto_plan.estimates['quality'] - plan.estimates['quality']) / plan.estimates['quality'] if plan.estimates['quality'] > 0 else 10.0
                )
                dist = time_dist + cost_dist + quality_dist
                if dist < min_dist:
                    min_dist = dist
                    min_dist_idx = idx

            min_distances.append((min_dist, min_dist_idx))

        # sort based on distance
        min_distances = sorted(min_distances, key=lambda tup: tup[0])

        # add k closest plans to final_plans
        k = min_plans - len(final_plans)
        k_indices = list(map(lambda tup: tup[1], min_distances[:k]))
        for idx in k_indices:
            final_plans.append(physical_plans[idx])

        return final_plans

    def generate_plans(self, logical_plan: LogicalPlan, sentinels: bool=False) -> List[PhysicalPlan]:
        """Return a set of possible physical plans."""
        # only fetch sentinel plans if specified
        if sentinels:
            models = getModels()
            assert (
                len(models) > 0
            ), "No models available to create physical plans! You must set at least one of the following environment variables: [OPENAI_API_KEY, TOGETHER_API_KEY, GOOGLE_API_KEY]"
            sentinel_plans = [self._createSentinelPlan(logical_plan, model) for model in models]
            return sentinel_plans

        # compute all physical plans for this logical plan
        physicalPlans = [
            physicalPlan
            for physicalPlan in self._createPhysicalPlans(logical_plan)
        ]
        print(f"INITIAL PLANS: {len(physicalPlans)}")
        return physicalPlans

    # def generate_plans(self, logical_plan: LogicalPlan) -> List[PhysicalPlan]:
    #     """Return a set of possible physical plans."""

    #     # Stub of physical planning code
    #     for logical_op in logical_plan:
    #         applicable_ops = [
    #             phy
    #             for phy in self.physical_ops
    #             if phy.inputSchema == logical_op.inputSchema
    #             and phy.outputSchema == logical_op.outputSchema
    #         ]  # Here this should be double checked
